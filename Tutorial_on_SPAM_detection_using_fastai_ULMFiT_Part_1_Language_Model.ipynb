{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial on SPAM detection using fastai ULMFiT - Part 1: Language Model",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pablo14/deeplearning/blob/master/Tutorial_on_SPAM_detection_using_fastai_ULMFiT_Part_1_Language_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCu-r6oRWpm6",
        "colab_type": "text"
      },
      "source": [
        "# Tutorial on SPAM detection using fastai ULMFiT - Part 1: Language Model\n",
        "\n",
        "tl;dr: We will walk through the creation of a language model, using a pre-traied network developed by the `fastai` team. Then we will see how known, and unknown word are handled in a way such that the semantic representation of them (embeddings) can be learrnt from the context.\n",
        "\n",
        "I wrote this post in collaboration with Pablo Zivic, who introduced me in this _deep_ and amazing world of transfer learning. Thanks Z.! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTjusEeaZBzv",
        "colab_type": "text"
      },
      "source": [
        "### The starting point"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsMgf8LLsoOq",
        "colab_type": "text"
      },
      "source": [
        "First we need to install torch and fastai in the google collab session:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L-mYNWDBB4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 808
        },
        "outputId": "1bc8590e-a4cb-4377-88d0-c66aee02b819"
      },
      "source": [
        "# Installing torch_nightly and fastai \n",
        "!pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
        "!pip install fastai"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
            "Collecting torch_nightly\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/nightly/cu92/torch_nightly-1.2.0.dev20190805%2Bcu92-cp36-cp36m-linux_x86_64.whl (704.8MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 704.8MB 25kB/s \n",
            "\u001b[?25hInstalling collected packages: torch-nightly\n",
            "Successfully installed torch-nightly-1.2.0.dev20190805+cu92\n",
            "Requirement already satisfied: fastai in /usr/local/lib/python3.6/dist-packages (1.0.59)\n",
            "Requirement already satisfied: fastprogress>=0.1.19 in /usr/local/lib/python3.6/dist-packages (from fastai) (0.1.22)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai) (4.6.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (4.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (0.25.3)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai) (1.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai) (0.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.17.4)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.1.9)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai) (0.4.2)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.3.1)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai) (7.352.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.21.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai) (2.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai) (19.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (3.1.2)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->fastai) (0.46)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2.6.1)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (2.0.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.2.0)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.9.6)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.2.4)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (7.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (2.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->fastai) (1.12.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->fastai) (2.4.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy>=2.0.18->fastai) (4.28.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->fastai) (42.0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA87AbrrBigr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import libraries\n",
        "\n",
        "from fastai import * \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "import io\n",
        "import os\n",
        "from fastai.text import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz5vzTnsCf5H",
        "colab_type": "text"
      },
      "source": [
        "Download SPAM data / TODO: Make  it from original UCI source..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQf44JDCK7td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
        "url='https://raw.githubusercontent.com/pablo14/ulmfit-spam-detector/master/SMSSpamCollection'\n",
        "df1 = pd.read_csv(url, sep='\\t',  header=None, names=['target', 'text'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzPteN5VMgPP",
        "colab_type": "code",
        "outputId": "ec80dca6-8b72-4bfc-c0c2-e998a60271e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "df1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will √º b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     target                                               text\n",
              "0       ham  Go until jurong point, crazy.. Available only ...\n",
              "1       ham                      Ok lar... Joking wif u oni...\n",
              "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3       ham  U dun say so early hor... U c already then say...\n",
              "4       ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...     ...                                                ...\n",
              "5567   spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568    ham               Will √º b going to esplanade fr home?\n",
              "5569    ham  Pity, * was in mood for that. So...any other s...\n",
              "5570    ham  The guy did some bitching but I acted like i'd...\n",
              "5571    ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnCNJjeVZAN2",
        "colab_type": "text"
      },
      "source": [
        "### Checking the target distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tyS2j30JWHTE",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2Mqt2J2ZDA_",
        "colab_type": "text"
      },
      "source": [
        "You might question.. what is `ham`? is it eatable?\n",
        "Google has the answer: \n",
        "\n",
        "> \"Ham\" is e-mail that is not Spam. In other words, \"non-spam\", or \"good mail\".\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SXRszhllc-E",
        "colab_type": "text"
      },
      "source": [
        "### Split training / test set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlN4i_Nr5Nhj",
        "colab_type": "text"
      },
      "source": [
        "Split the data now won't make much sense in this part 1. It will be used in the classification part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK_i0X2kD6AC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split data into training and validation set\n",
        "df_trn, df_val = train_test_split(df1, stratify = df1['target'], test_size = 0.3, random_state = 999)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0xrLS3bqGGf",
        "colab_type": "code",
        "outputId": "99a295e2-11c4-48c9-fbfb-22c908cf2768",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df_trn.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4853</th>\n",
              "      <td>ham</td>\n",
              "      <td>I liked your new house</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2511</th>\n",
              "      <td>ham</td>\n",
              "      <td>Yunny i'm walking in citylink now √º faster com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4011</th>\n",
              "      <td>spam</td>\n",
              "      <td>Wan2 win a Meet+Greet with Westlife 4 U or a m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3899</th>\n",
              "      <td>ham</td>\n",
              "      <td>Otherwise had part time job na-tuition..</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>653</th>\n",
              "      <td>ham</td>\n",
              "      <td>Wait, do you know if wesleys in town? I bet sh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     target                                               text\n",
              "4853    ham                             I liked your new house\n",
              "2511    ham  Yunny i'm walking in citylink now √º faster com...\n",
              "4011   spam  Wan2 win a Meet+Greet with Westlife 4 U or a m...\n",
              "3899    ham           Otherwise had part time job na-tuition..\n",
              "653     ham  Wait, do you know if wesleys in town? I bet sh..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYEFCrJOEHSG",
        "colab_type": "code",
        "outputId": "2f3dd59e-3df3-401b-811e-ce93345050b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df_trn.shape, df_val.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3900, 2), (1672, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvvFWWM4ljoH",
        "colab_type": "text"
      },
      "source": [
        "### Data for the *Language Model* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tNP_aMTEOKe",
        "colab_type": "code",
        "outputId": "c92a3f84-7cc4-4064-9eb9-b29d9810a985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "# Language model data\n",
        "data_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = df_val, path = \"\")\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VnUl3hVEPhg",
        "colab_type": "text"
      },
      "source": [
        "`itos` contains the pairs id-word from our data. The id is the position. This is the **numericalization** step.\n",
        "\n",
        "Each word is represented with a number (position in the vector)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVZ6PXsQH_oT",
        "colab_type": "code",
        "outputId": "f7e456b9-4b22-42ec-ddbb-f851a0e30b32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "data_lm.train_ds.vocab.itos[0:30]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xxunk',\n",
              " 'xxpad',\n",
              " 'xxbos',\n",
              " 'xxeos',\n",
              " 'xxfld',\n",
              " 'xxmaj',\n",
              " 'xxup',\n",
              " 'xxrep',\n",
              " 'xxwrep',\n",
              " '.',\n",
              " 'i',\n",
              " 'to',\n",
              " 'you',\n",
              " ',',\n",
              " '?',\n",
              " 'a',\n",
              " 'the',\n",
              " '!',\n",
              " '...',\n",
              " 'u',\n",
              " 'and',\n",
              " 'is',\n",
              " 'in',\n",
              " 'my',\n",
              " 'me',\n",
              " 'for',\n",
              " '..',\n",
              " 'it',\n",
              " 'your',\n",
              " 'do']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYJ4EDQqFno_",
        "colab_type": "text"
      },
      "source": [
        "Those strange words such as `xxbos`, `xxmaj`, etc -also seen in the `itos` list, are tokens that will the neural network to learn patterns.\n",
        "Check the full list in the documentation: https://docs.fast.ai/text.transform.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep88_n4MFJ15",
        "colab_type": "text"
      },
      "source": [
        "We can plot the training data for our language model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdemHo0CmUx8",
        "colab_type": "code",
        "outputId": "b135b42f-b832-4ee4-f778-f144c7486bd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "data_lm.show_batch()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>otherwise had part time job na - tuition .. xxbos xxmaj wait , do you know if xxunk in town ? i bet she does hella drugs ! xxbos xxmaj so what did the bank say about the money ? xxbos i probably wo n't eat at all today . i think i 'm gon na pop . xxmaj how was your weekend ? xxmaj did u miss me ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>need to write xxbos xxmaj free xxmaj msg : xxunk : http : / / tms . widelive.com / index . xxunk * xxunk = xxunk xxbos i not at home now lei ... xxbos xxmaj can you let me know details of fri when u find out cos i 'm not in tom or fri . xxunk chinese . xxmaj thanks xxbos i know a few people i can</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>search job : ) xxbos xxmaj where at were hungry too xxbos xxmaj urgent ! call xxunk from xxmaj landline . xxmaj your complimentary 4 * xxmaj tenerife xxmaj holiday or ¬£ 10,000 cash await collection xxup sae t&amp;cs xxup box xxunk xxup xxunk xxup xxunk 150ppm 18 + xxbos xxmaj where @ xxbos 18 days to xxmaj euro2004 xxunk ! u will be kept informed of all the latest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>national = rate call . xxbos xxmaj u're welcome ... xxmaj caught u using broken english again ... xxbos xxmaj eek that 's a lot of time especially since xxmaj american xxmaj pie is like 8 minutes long . i ca n't stop singing it . xxbos xxmaj but you dint in touch with me . xxbos xxmaj yes but i do n't care cause i know its there !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>even she become quite black .. and ur rite here its too cold , wearing xxunk .. xxbos xxmaj sorry , i 'll call you later . i am in meeting sir . xxbos xxmaj tick , tick , tick ... xxmaj babe xxbos xxmaj yes princess ! i want to please you every night . xxmaj your wish is my xxunk ... xxbos xxmaj i.ll post her out l8r</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk4sc96FGlJj",
        "colab_type": "text"
      },
      "source": [
        "### Let's create the language model! üßô‚Äç‚ôÇÔ∏è‚ú®"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EMfvm067vf1",
        "colab_type": "text"
      },
      "source": [
        "Esentially, the language model contains the structure of the language (English in this case), allowing us to quickly use in a classification model, skipping the part of learning the semantics of the language from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ua8pmHEEP5N",
        "colab_type": "code",
        "outputId": "270912e0-a623-485e-f3b5-9aed7727093a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "lang_mod = language_model_learner(data_lm,  arch = AWD_LSTM, pretrained = True, drop_mult=1.)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGMhOVVVRWjV",
        "colab_type": "text"
      },
      "source": [
        "We've just download the pre-trained model, which is a neural network (NN) with an `AWD_LSTM` architecture.  By setting `pretrained = True` we say to fastai to download the weights from the trained model (a corpus of 103 MM of wikipedia articles).\n",
        "\n",
        "\n",
        "\n",
        "Basically instead of representing the words as embeddings (one layer) and retrain every time we need create the model, we are using a NN which has the semantic of the words in a context.\n",
        "\n",
        "You can find more information in: [Universal Language Model Fine-tuning for Text Classification](https://arxiv.org/abs/1801.06146) by Jeremy Howard and Sebastian Ruder \n",
        "\n",
        "####  But what is an embedding? \n",
        "\n",
        "Just in case you are too new to NLP, we've just talked about a lot of terms and concepts. By now, we are not going to cover it too deeply. Please check the course: https://www.fast.ai/2019/07/08/fastai-nlp/\n",
        "\n",
        "Each word is a vector, for example:\n",
        "\n",
        "`hello` is translated into `[0.32, 0.1, 0.5]`. These 3 numbers will be similar to other word that is used in the same context of the text. For example : `hi`. The vector (embedding) for `hi` can be: `[0.30, 0.1, 0.49]`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFTjoeFOk-2E",
        "colab_type": "text"
      },
      "source": [
        "_Spending too much reading numbers, will give you the superpower of reading sentences using strange symbols, just like Neo!_\n",
        "\n",
        "![alt text](https://media.giphy.com/media/Q9aBxHn9fTqKs/giphy.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJvSVtephixx",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD0gG9Et7p0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO1QrcaY7qMI",
        "colab_type": "text"
      },
      "source": [
        "## Testing the language model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvqIOo4Y7s1E",
        "colab_type": "text"
      },
      "source": [
        "The language model has been created, so now we can test it generating some random sentences (the most simplest _naive deep fake_).\n",
        "\n",
        "We can test the language by simply call the `predict` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qxcCoAzh5vw",
        "colab_type": "code",
        "outputId": "e27a46ce-3b42-4b36-faf1-6a4407c4537a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "for i in range(5):\n",
        "  print(lang_mod.predict(\"The problem usually starts when\", n_words=10))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The problem usually starts when smart Mad Men people come down to the\n",
            "The problem usually starts when we decide to stop over and advance to a friend\n",
            "The problem usually starts when a single - issue package 's weight is lost ,\n",
            "The problem usually starts when either one has to concentrate or almost blame their members\n",
            "The problem usually starts when in the second half of the game , the need\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REYOKfQ1ibub",
        "colab_type": "text"
      },
      "source": [
        "Each time we excecute the `predict`, we get a different random sentence, completed with the number of choosen words (`n_words`).\n",
        "\n",
        "Try your own sentences! ü§ì\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyUNhkaw--jK",
        "colab_type": "text"
      },
      "source": [
        "### More about the language model\n",
        "\n",
        "‚ö†Ô∏è[Oversimplifying] If sentences makes sense, it's because the training on the wikipedia corpus. Later on, we will adjust a little this model in order to learn the represntations of our particular problem (SPAM detection).\n",
        "\n",
        "This way, we will save huge amounts of time. Let's say we learn the semantics of English, and then we will adjust it to our particular case.\n",
        "\n",
        "Medicine and Laws have very different termns, but at the same time, the underlying English structure is the same.\n",
        "\n",
        "If we make use of the undeerlying structure, and then we learn the particularities of our problem, we are doing something that is called **transfer learning**.\n",
        "\n",
        "For an overview about Transfer Learning, check: [What is transfer learning? by Nvidia](https://blogs.nvidia.com/blog/2019/02/07/what-is-transfer-learning/) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTPzpU6dfMYJ",
        "colab_type": "text"
      },
      "source": [
        "## Inspecting old vs new tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MXXYFqvfSyZ",
        "colab_type": "text"
      },
      "source": [
        "Now we are going to download the tokens from the pre-trained model. Remember the `itos` from our data? Well this is the same but using the pre-trained model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkJJmlHQKs52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open('/root/.fastai/models/wt103-fwd/itos_wt103.pkl', 'rb') as f:\n",
        "  orig_itos = pickle.load(f)\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uE91QelhpxK",
        "colab_type": "code",
        "outputId": "3fad496c-a11c-4834-98ac-0829082efbf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Total number of tokens:\n",
        "len(orig_itos)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AerMOtuxfJZ1",
        "colab_type": "text"
      },
      "source": [
        "Next step will compare the tokens that exists in both dictionaries (pre-trained vs spam data).\n",
        "\n",
        "And what tokens are not present in the pre-trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMGU08uPN21N",
        "colab_type": "code",
        "outputId": "020043bb-13be-41a6-d97f-370740bd2165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "old_tokens = list(set(data_lm.vocab.itos).intersection(orig_itos))\n",
        "new_tokens = list(set(data_lm.vocab.itos) - set(orig_itos))\n",
        "\n",
        "len(old_tokens), len(new_tokens)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2690, 862)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQkqbfZGqj-c",
        "colab_type": "text"
      },
      "source": [
        "2690 tokens are present in the pretrained, while 862 aren't.\n",
        "\n",
        "Some of the new tokens are:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJuUY1lFqmbF",
        "colab_type": "code",
        "outputId": "61a94fac-31bc-4f26-c9d5-21707709247e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "new_tokens[:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['goodmorning',\n",
              " 'minuts',\n",
              " 'phne',\n",
              " 'ibh',\n",
              " '008704050406',\n",
              " '84025',\n",
              " '2lands',\n",
              " '-message',\n",
              " 'w45wq',\n",
              " 'hlp']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngZ3QoOOix-A",
        "colab_type": "text"
      },
      "source": [
        "It means that there are certain words now on our SPAM data, that were not present in the wipikedia corpus.\n",
        "\n",
        "The question that arises is, how we are going to handle these new tokens for our model? The absense of these tokens imply that the embedding is initialized randomly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ9EfizFrCjN",
        "colab_type": "text"
      },
      "source": [
        "## Let's play with the data, and learn! üîéüìñ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Iu787AirLPt",
        "colab_type": "text"
      },
      "source": [
        "Now, we are going to see the similitudes between two words by comparing their embeddings.\n",
        "\n",
        "To this end, next functions will help us to normalize the embeddings' weights,  and to return, based on a single token (word), the top 10 most similar tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwx7YJDVO1IN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn import functional as F\n",
        "\n",
        "def get_normalized_embeddings():\n",
        "  return F.normalize(lang_mod.model[0].encoder.weight)\n",
        "\n",
        "def most_similar(token, embs):\n",
        "  idx = data_lm.vocab.itos.index(token)\n",
        "  sims = (embs[idx] @ embs.t()).cpu().detach().numpy()\n",
        "\n",
        "  print(f'Similar to: {token}')\n",
        "  for sim_idx in np.argsort(sims)[::-1][1:11]:\n",
        "    print(f'{data_lm.vocab.itos[sim_idx]:<30}{sims[sim_idx]:.02f}')\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-mk92srsXio",
        "colab_type": "text"
      },
      "source": [
        "### Checking token similarity for old tokens\n",
        "\n",
        "These tokens should be ok, since the embeddings were learnt based on a big wikipedia corpus...\n",
        "\n",
        "We will pick some random word, from the old tokens and we will check their similarities. \n",
        "\n",
        "\n",
        "_You can play with this by exectuting the cell several times and check what happens!_ üéÆ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXTsj7kVsWwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalizing the embeddings.\n",
        "embs_v1 = get_normalized_embeddings()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwztAcgv6zjA",
        "colab_type": "text"
      },
      "source": [
        "We saved the embeddings so we can improve the network and check the results üòâ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npd7YRUSOTEj",
        "colab_type": "code",
        "outputId": "203d691a-891c-43ba-eaed-c128fd748b12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "from random import choice\n",
        "\n",
        "old_token = choice(old_tokens) # picking a random word\n",
        "most_similar(old_token, embs_v1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similar to: issues\n",
            "problems                      0.58\n",
            "issue                         0.57\n",
            "difficulties                  0.42\n",
            "questions                     0.41\n",
            "problem                       0.38\n",
            "affairs                       0.34\n",
            "pages                         0.33\n",
            "reasons                       0.33\n",
            "changes                       0.30\n",
            "decisions                     0.29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrsmOy7x_jGr",
        "colab_type": "text"
      },
      "source": [
        "For a particular word:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtZhP1HT_icR",
        "colab_type": "code",
        "outputId": "b3c301b0-0074-4d36-a6df-f146aa96129b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "most_similar('nice', embs_v1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similar to: nice\n",
            "lovely                        0.54\n",
            "cute                          0.52\n",
            "wonderful                     0.52\n",
            "funny                         0.50\n",
            "fantastic                     0.47\n",
            "pretty                        0.46\n",
            "stupid                        0.46\n",
            "horrible                      0.44\n",
            "weird                         0.44\n",
            "interesting                   0.43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1Tpau3-AY5Y",
        "colab_type": "text"
      },
      "source": [
        "What we see is the word `nice` is similar to `lovely` (because both are used in similar context, don't you think?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-wED2nrtyz2",
        "colab_type": "text"
      },
      "source": [
        "Now we will do the same, but using the new tokens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqwLAPUhP3Ef",
        "colab_type": "code",
        "outputId": "6efc4f45-137e-4328-d844-08c4e88b23d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "# Random word:\n",
        " new_token = choice(new_tokens)\n",
        " most_similar(new_token, embs_v1)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similar to: ranjith\n",
            "g696ga                        1.00\n",
            "nurungu                       1.00\n",
            "minnaminunginte               1.00\n",
            "11mths                        1.00\n",
            "aiyah                         1.00\n",
            "w1                            1.00\n",
            "08718720201                   1.00\n",
            "83600                         1.00\n",
            "bleh                          1.00\n",
            "ppl                           1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n6DkrIFMkuI",
        "colab_type": "text"
      },
      "source": [
        "We will analyze the word `:)` (yes, the emoji face)\n",
        "\n",
        "Results will be interesting! üßô‚Äç‚ôÄÔ∏è"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og6oxtvi-r0i",
        "colab_type": "code",
        "outputId": "2d6ab0b5-dfcc-4d92-bf0e-5a4ab61319c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "# A particular word:\n",
        "most_similar(':)', embs_v1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similar to: :)\n",
            "g696ga                        1.00\n",
            "nurungu                       1.00\n",
            "minnaminunginte               1.00\n",
            "11mths                        1.00\n",
            "aiyah                         1.00\n",
            "w1                            1.00\n",
            "08718720201                   1.00\n",
            "83600                         1.00\n",
            "bleh                          1.00\n",
            "ppl                           1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zJN6TZD8yGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XemfuFuit4DZ",
        "colab_type": "text"
      },
      "source": [
        "We see that:\n",
        "\n",
        "A) Doesn't make any sense\n",
        "\n",
        "B) related to A), all the probabilities are 100%... we can see how the embeddings are initiallized randomly. We need to adjust our **Language Model**.\n",
        "\n",
        "This adjustment is called **fine-tunning**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrJo6UktBud9",
        "colab_type": "text"
      },
      "source": [
        "### Language Model Fine-Tuning \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRuJzfoZBqqY",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://media.giphy.com/media/xMY7fFxaQlyi4/giphy.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z97FIJ478Drb",
        "colab_type": "text"
      },
      "source": [
        "Now we will find the best learning rate (LR)\n",
        "\n",
        "_As the fastai documentation suggests, learn more about the lr_find() at: [ Cyclical Learning Rates for Training Neural Networks](https://)._\n",
        "\n",
        "\n",
        "Then we will train 4 epochs, using the `fit_one_cycle` function.\n",
        "This powerful technique will train, by now, only the last layer of our language model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK3061wu77jK",
        "colab_type": "code",
        "outputId": "aa4ca44f-95ba-4eb1-fcd7-b3330102e425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "lang_mod.lr_find()\n",
        "lang_mod.recorder.plot(suggestion=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
            "Min numerical gradient: 2.51E-01\n",
            "Min loss divided by 10: 6.31E-02\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd3hc5Zn38e+t3iXLkqts4053E2AC\nS2BJKMkmwAaykADBhBbKpu4bdnNterKbwiawLDjEBAIxbBJDNqRREkIgFAe54G5jy02ukmyrt5Hu\n948Z2ULIfc4Uze9zXXN55pxnzrlnPJp7nnKex9wdERFJXWnxDkBEROJLiUBEJMUpEYiIpDglAhGR\nFKdEICKS4jLiHcDRKisr8xNOOCHeYYiIJJVFixbVuXv5QPuSLhGccMIJVFVVxTsMEZGkYmabD7ZP\nTUMiIilOiUBEJMUpEYiIpLjAEoGZTTWzpX1ujWb2mX5lzMzuM7P1ZrbMzGYGFY+IiAwssM5id18L\nTAcws3RgG/CrfsUuBSZHbmcBD0b+FRGRGIlV09CFwAZ3799rfRnwmIe9AZSY2cgYxSQiIsQuEVwN\nPDnA9tHA1j6PayLb3sHMbjGzKjOrqq2tDShEEZHUFHgiMLMs4MPAL4/1GO7+kLtXuntlefmA10OI\niAxqP/zjOl55O5gfwrGoEVwKLHb3XQPs2waM6fO4IrJNREQi3J3/fnE9C6v3BHL8WCSCaxi4WQjg\nGeD6yOih2UCDu++IQUwiIkmjraub7h6nICeY8T2BTjFhZvnA+4Fb+2y7DcDd5wK/Bz4ArAdagTlB\nxiMikoya20MAFGQnYSJw9xZgaL9tc/vcd+COIGMQEUl2TR3hRFAYUI1AVxaLiCS43hqBEoGISIpq\n7uhtGsoM5PhKBCIiCa4p4D4CJQIRkQTX1N4FqGlIRCRlHWgaUiIQEUlJ+4ePqkYgIpKamjtC5GSm\nkZkezFe2EoGISIJr6ggFNmIIlAhERBJec3sosI5iUCIQEUl4Te1dgXUUgxKBiEjCa+4IKRGIiKSy\nJjUNiYiktuaOUGBDR0GJQEQk4TV3hChU05CISGpyd5raVSMQEUlZ7V094dXJdB2BiEhqauoITzin\nGoGISIrqnWeoSIlARCQ1BT3zKCgRiIgktKAXrgclAhGRhNYY8BTUoEQgIpLQepuGCpN11JCZlZjZ\nAjNbY2arzezsfvuLzew3ZvaWma00szlBxiMikmya24MfNRTckcPuBZ519yvNLAvI67f/DmCVu3/I\nzMqBtWY23907A45LRCQpxKKzOLAjm1kxcB5wA0Dky73/F7wDhWZmQAGwBwgFFZOISLJp6giRnZFG\nVkZwDThBNg2NB2qBR8xsiZnNM7P8fmXuB04CtgPLgU+7e0//A5nZLWZWZWZVtbW1AYYsIpJYgl6U\nBoJNBBnATOBBd58BtAB39ytzMbAUGAVMB+43s6L+B3L3h9y90t0ry8vLAwxZRCSxNLUHuxYBBJsI\naoAad18YebyAcGLoaw7wtIetBzYCJwYYk4hIUgl6CmoIMBG4+05gq5lNjWy6EFjVr9iWyHbMbDgw\nFagOKiYRkWTTHIMaQdCjhu4C5kdGDFUDc8zsNgB3nwt8A3jUzJYDBnzR3esCjklEJGk0dYSoGJIb\n6DkCTQTuvhSo7Ld5bp/924GLgoxBRCSZNXd0UZhdGOg5dGWxiEgCaw54URpQIhARSVj7VydL4lFD\nIiJyHDpCPYR6XDUCEZFU1dTeO+GcEoGISEraP/NoTnAzj4ISgYhIworFojSgRCAikrBisXA9KBGI\niCSsJtUIRERSW2/TUDLPPioiIschFovSgBKBiEjC2p8IVCMQEUlNTe0hsjLSyM5ID/Q8SgQiIgkq\nPOFc0JNEKxGIiCSsphhMOAdKBCIiCSsWi9KAEoGISMJq6lAiEBFJac3tocDnGQIlAhGRhNXcEQr8\nYjJQIhARSVhN7V1qGhIRSVXuTnOHRg2JiKSsjlAPXd2e/DUCMysxswVmtsbMVpvZ2QOUOd/MlprZ\nSjP7S5DxiIgkiwOL0gSfCII+w73As+5+pZllAXl9d5pZCfAAcIm7bzGzYQHHIyKSFGI18ygEmAjM\nrBg4D7gBwN07gc5+xT4GPO3uWyJldgcVj4hIMjkw82hyDx8dD9QCj5jZEjObZ2b5/cpMAYaY2Utm\ntsjMrh/oQGZ2i5lVmVlVbW1tgCGLiCSGxvbI6mRJ3keQAcwEHnT3GUALcPcAZWYBHwQuBv7dzKb0\nP5C7P+Tule5eWV5eHmDIIiKJIZZNQ0Emghqgxt0XRh4vIJwY+pd5zt1b3L0OeBmYFmBMIiJJIVaL\n0kCAicDddwJbzWxqZNOFwKp+xX4NnGtmGWaWB5wFrA4qJhGRZBGrRWkg+FFDdwHzIyOGqoE5ZnYb\ngLvPdffVZvYssAzoAea5+4qAYxIRSXhNg2HUEIC7LwUq+22e26/M94DvBRmHiEiyae4IkZUe/Opk\noCuLRUQSUlN7V0yahUCJQEQkIe1p6WRIXvDXEIASgYhIQqpr6qSsIDsm51IiEBFJQHUtHUoEIiKp\nrK6pg7KCrJicS4lARCTBdIZ6aGwPMVQ1AhGR1FTf0gGgpiERkVRV1xSeqFlNQyIiKaouUiNQ05CI\nSIqqawongnIlAhGR1FTfEm4aGqqmIRGR1FTX1EFuZjr5MZiCGpQIREQSTn1LZ8xqA6BEICKScOqa\nY3dVMSgRiIgknLrm2M0zBEoEIiIJJ1wjUNOQiEhK6ulx9rSoRiAikrL2tXXR3ePqLBYRSVV1zbGd\nZwiUCEREEkpvIlCNQEQkRdU1h68qjtX0EhBwIjCzEjNbYGZrzGy1mZ19kHJnmFnIzK4MMh4RkURX\n3xzbCecAgr5++V7gWXe/0syygLz+BcwsHfgO8HzAsYiIJLy65g7S04yS3NgsXA8B1gjMrBg4D3gY\nwN073X3fAEXvAp4CdgcVi4hIsqhv7mRofhZpaRazcwbZNDQeqAUeMbMlZjbPzPL7FjCz0cAVwIMB\nxiEikjTqmjti2iwEwSaCDGAm8KC7zwBagLv7lfkh8EV37znUgczsFjOrMrOq2traYKIVEUkAtc2d\nMb2qGI4wEZjZRDPLjtw/38z+2cxKDvO0GqDG3RdGHi8gnBj6qgT+18w2AVcCD5jZ5f0P5O4PuXul\nu1eWl5cfSchJZ19rJ1v3tMY7DBGJs/oYTzgHR95Z/BRQaWaTgIeAXwNPAB842BPcfaeZbTWzqe6+\nFrgQWNWvzPje+2b2KPBbd/+/o3sJwdvV2E5LR4gxpXlkph/InW2d3azf3UxtczsZaWlkpBtZ6WlM\nGlZASd6hM3pnqIffLd/OGxv2sGjLXtbvbgbg4lOG8/mLpjJleOH+sl3dPWyub2FYUQ5FObHrQBKR\n2HL3mM8zBEeeCHrcPWRmVwD/7e7/bWZLjuB5dwHzIyOGqoE5ZnYbgLvPPbaQY2fJlr3Me2Ujf1ix\ngx6H9DRjbGkeI4pyqNnXSs3eNtzf/bw0g1njhnDBicM4f8owpgwvICOSQELdPTy9ZBv3/vFttu1r\noyQvk1ljh3DFjNF0dHXzk1c38fyql7ls2ijGDs3nzY17WLJ1L+1d4dazsoIsJpQVMKE8n/Fl4duE\n8nxOGJq//xxBc3c217dSkpd52IQnIkeutbOb9q6emPcRHGki6DKza4BPAB+KbDvsT1N3X0q4+aev\nAROAu99whLEEbmF1Pd9/fi1vbtpLYU4GN583gcnDCtlU18LGuha2N7QxraKEq2aNYcrwAoYX5dDj\nTle3097VzaLNe3lxzW6+++xavvvs2v21hBNHFLJ06z6q61qYVlHMt//xNM6bXIbZgdEBc84Zz49e\nrubR1zbSGerhpJFFXH3GWE4bXUxtcwcba1uormvmhVW79i9nB5CdkcaJIwo5ZXQx08eU8OFpo8jJ\nTD/u98LdaWwPsaOhjVXbG/nr23X8dX0duyNrqo4vy2f6mBImDy+gvauHxrYuGtu7GF6UwwdPG8kp\no4re8fqOR0eom411Lazb1cz6XU1sqm+lIXK+xrYuCnIyOW10EaeNLubU0cVMLC+IynsgEivxmF4C\nwHygn7T9C5mdDNwGvO7uT5rZeOCj7v6doAPsr7Ky0quqqo76eQ2tXby5aQ9/N6WM7IyBvxzqmjv4\n9u9X8/TibYwqzuGmv5vAR88YQ8ExLhe3q7Gd1zbUsWZHE2t2NrFmZyNlBdl8+sLJvP/k4Yf8gmxq\n7wKg8BBNQQ1tXWyqa2FDbTNrdjaxYlsDK7Y10NgeYlhhNnf+/ST+6YwxB329Ax1v5fbwMZZva2TN\njka272ujpbN7f5nS/CzOmVTG7Aml7GvtYunWfSzduo/aSGIozMmgKCeTXY3thHqc8WX5fOC0EYwu\nySMrI43sjDSccJ/I3pYu9rZ2kpluDMnPYmh+FkU5mbR0dtPY1kVDWxe7mzrYsqeFTXWt7Ghooyfy\ncU0zqBiSx5C8TIpyMynMyWBPSycrtzXS1BECwAwqhuQyoayAsaV5FOVmUJCdSUFOBvXNHazf3cz6\n3c3saGhn8rACpo8pYfrYEqZVlFAxJDdqCUzkSC3avJePPPgaj8w5gwumDovqsc1skbv3/2Ee3nck\niaDfwYYAY9x9WTSCO1rHmgh+8eZW/t9TyyjMyeCik0fwD6ePZOqIQva0dFLf0sm6nU3c/+f1tHaG\nuOW8Cdx5wWRys5Lv16S7s3DjHv7r+XX8bdMeRpfkcv7UchrautjX2kVTexel+VlUDMmjYkgumelp\nrNjWwNKafVTXtuw/zqjiHE4eVcyY0lxGFecysiSHCWXhWk3/8c3uTktnN7mZ6aRH9u1p6eTZFTv5\n7bLtvFFdv/8LvL/C7Ay6enr2N331V5qfxbiheYwrzWPs0HwmDStg8rBw09hACa6nx9m8p5UV2xrY\nUNvMhtoWqmub2bavjab2EN2RQMxgzJA8Jg0rYHhRNmt3NrFieyOdoXAcJXmZnDa6mFNGFTOiKJvC\nnHCyGVGcw2mji5UkJBDPrdzJrY8v4rd3ncupo4ujeuzjTgRm9hLwYcJNSYsIX/z1qrt/LopxHpFj\nTQSdoR5e3VDH75bt4LmVO2lqD72rzOwJpXzz8lOZNKxwgCMkF3fnr+vr+OEf32ZDbTND8rIoycuk\nMCeT+uYOava20dAWrnWUF2YzraKE6WPCTSqnjS6Oahtlc0eIlo4QHV09dHZ34w4lkXh6O9/bOrup\nb+mgsS1EQXYGRbkZFOZk7k8s0eDutHV109weoig3813NRp2hHtbubOKtmn2RWlED63Y10dX9zr+R\nU0cXcet5E7n01BEx65eR1PDEwi3826+W88a/XsiI4pyoHjsaiWCJu88ws5sI1wa+YmbL3P30qEZ6\nBI41EfTVGerh1fV17GhoZ2hBFmUFWZQVZDO2NC+lfuk1tnfR3tlNeWF2Sr3uo9HV3UNTe4im9i4a\n20Is39bAvFeqqa5rYUxpLh+eNorJwwqZWB6upeQfYzOiCMB9f3qb/3phHeu+eSlZGdH9kXGoRHCk\nn9oMMxsJfBT4UtQii5OsjDQuODG67W/JqCgnU8NRDyMzPY3S/CxK88Ojo06rKObqM8bwwupdzHul\nmrl/qd7f3AQwoTyf6RUlTBtTwpnjSzlpZFG8QpckVNfcQXFuZtSTwOEcaSL4OvAc4eagN81sAvB2\ncGGJJK60NOPiU0Zw8Skj6AyFr/HYUNvMul3NLKtp4OW363h6yTYApo0p4dqzxvKhKI3iksGtvrkz\npusQ9DrqzuJ4i0bTkEiQ3J0dDe08v3InP1u4hfW7mynOzeTqM8cw5z3jo972K4PHR3/0OgC/uHXA\nGfuPy6Gaho50iokKM/uVme2O3J4ys4rohikyOJgZo0pyueGc8bzw2fN48ubZnDupjB+/XM2533mR\nz/1iKau2N5JsP8IkePVxuKoYjrxp6BHCU0pcFXl8bWTb+4MISmSwMDPOnjiUsycOZeueVh7+60Z+\nUbWVpxdvo6wgmxljS5gxtoRZY4cwbUyJmo9SXF1zJ+fE+GIyOPJEUO7uj/R5/KiZfSaIgEQGqzGl\neXz1w6fwmfdN5rfLdrB4y16WbtnHC6t2AeGrw2eOHcJZE0qZVlHCSSOLGF6kEV2pojPUQ0NbV8yv\nKoYjTwT1ZnYt8GTk8TVAfTAhiQxuJXlZXDt7HNfOHgfA3pZOqjbv5Y3qet6orufeP729fw6rkrxM\nplWUcOO54981HYkMLnsiU8bEo7P4SBPBjcB/Az8AHHgNuCGgmERSypD8LN5/8nDef/JwIHx9R3ha\nkkZW72jkpbW1fOInf2NaRTF3/f1kLjxpmBLCINQ7z9DQ/AStEbj7ZsJXFu8XaRr6YRBBiaSyopxM\nzhxfypnjS4Fwk8FTi2t44KX13PRYFVOGF3Dd2SdwxYzRxzwPliSeXY3tAHEZVXY8Vy3EfHoJkVSU\nlZHGNWeO5cXPn889V00jKyONf/+/FZz1rT/y7/+3QgsaDRI7GiKJoCj2ieB4fk6obioSQ5npaXxk\nVgX/OHM0b9U08Pjrm/l51VZ+/uZWPj57LHdeMCnm89hL9OxsaCc9zSgvTNCmoYPQIGiRODCz8JTZ\nY0r4wsVTuPePb/PT1zbxy6oaPnX+RG49b4Imw0tCOxvbGVaYHdWJFo/UIT8tZtZkZo0D3JqAUTGK\nUUQOYmRxLv/5kdN5/rPv5ZxJQ/nec2v5+LyF7I60N0vy2NnQHrerzg+ZCNy90N2LBrgVurt6qUQS\nxKRhBfzoukruuWoay2oa+MB9f+W1DXXxDkuOwo6GNkYmYiIQkeTykVkV/PrOcyjOzeDaeQu5/8W3\n6TnYqkCSMHrnpxpRlBuX8ysRiAwyU4YX8syd5/IPp4/i+8+v49afLaIxsvSpJKamjhCtnd2MKI5P\nZ78SgcgglJ+dwb1XT+fL/3Ayf16zm8vuf5W1O5viHZYcxK7eoaPFqhGISBSZGTeeO54nbp5Nc0eI\ny//nVfUbJKjeawgGZR+BmZWY2QIzW2Nmq83s7H77P25my8xsuZm9ZmbTgoxHJBWdOb6U3951LhVD\ncvnko1W8uWlPvEOSfnbG8WIyCL5GcC/wrLufCEwDVvfbvxF4r7ufBnwDeCjgeERS0vCiHObffBYj\ni3OY88ibLN26L94hSR+9NYLhgy0RmFkxcB7wMIC7d7r7Oz597v6au++NPHwD0GI3IgEZVpjDEzfP\npjQ/i+sfXsiKbQ3xDkkidja2UVaQFfO1insFedbxQC3wiJktMbN5ZpZ/iPKfBP4w0A4zu8XMqsys\nqra2NohYRVLCiOIcnrj5LApzMvnYj99Qn0GCiOfFZBBsIsgAZgIPuvsMoAW4e6CCZnYB4UTwxYH2\nu/tD7l7p7pXl5eVBxSuSEiqG5PHzW2czvCiH6x/+GwsW1cQ7pJQXz2sIINhEUAPUuPvCyOMFhBPD\nO5jZ6cA84DJ312I3IjFQMSSPBZ96D2dNKOULv3yL/3p+rdZQjqOdje1xGzEEASYCd98JbDWzqZFN\nFwKr+pYxs7HA08B17r4uqFhE5N2KczN55IYz+WhlBfe9uJ5/WbCMUHdPvMNKOW2d3exr7Ypr01DQ\n8wXdBcw3syygGphjZrcBuPtc4MvAUOCByIpLIXevDDgmEYnIykjjOx85nZHFudz7p7dpbg9x7zXT\nyc5Ij3doKWNnY3yHjkLAicDdlwL9v9jn9tl/E3BTkDGIyKGZGZ99/xSKczP5+m9XcdNPq5h77Szy\ntfpZTOyM88VkoCuLRSTixnPH8/2rpvHq+jqufXghzR2heIeUEnY2tgHxWaKylxKBiOx35awKHvj4\nLJbVNHDzT6to7+qOd0iD3v4lKpUIRCRRXHLqCO65ahqvV9dz15NL1IEcsJ0N7RTnZpKXFb+mOCUC\nEXmXy2eM5msfPoUXVu3i7qeXa02DAIWvIYhfbQCCHzUkIknqE+85gb2tnfzwj28zND+Lf/3ASfEO\naVDa1Rjfq4pBiUBEDuHTF06mrrmDH71czeThhVw5S9OBRduOhnZOHlkU1xjUNCQiB2VmfOVDp/Ce\niUP5t6eXs2jz3sM/SY5YZ6iHuuaOuNcIlAhE5JAy09P4n4/NZGRJDrc+vogdDW3xDmnQ2N3Ujnt8\nryEAJQIROQJD8rOYd30l7V3d3PxYFW2dGlYaDTvjvA5BLyUCETkik4cXcu/V01m5vZG7n16mSeqi\n4MASlfGbeRSUCETkKFx40nC+cNFUfr10Oz9+pTre4SS9XY3xv5gMlAhE5Cjdfv5EPnDaCP7zD2t4\neZ0WijoeOxrayctKpygnvgM4lQhE5KiYGd+7chpThhdy15NL2FzfEu+QklbvymSR2ZfjRolARI5a\nfnYGD11XiRnc/FgVDW1d8Q4pKe1oaIv7VcWgRCAix2js0Dwe+NhMNta1cNvji+gIaSTR0dq2r41R\nJfHtKAYlAhE5Du+ZVMZ3rzyd16vr+ZdfLtOcREehrbObXY0dnDA0L96haIoJETk+V8yoYEdDO999\ndi2jSnK5+9IT4x1SUtiypxWAsUPz4xyJEoGIRMGn3juR7fvamPuXDYwekst1s8fFO6SEtynSya4a\ngYgMCmbG1z58Ktv3tfO1Z1YyZVgBZ00YGu+wElrvaKtxpfGvEaiPQESiIj3N+OHV0xlbmscdTyxm\n+z7NSXQom+tbKcnLpDgvM96hKBGISPQU5WTy0PWzaO/q4VM/W6SlLg9hc30r4xKgfwACTgRmVmJm\nC8xsjZmtNrOz++03M7vPzNab2TIzmxlkPCISvEnDCvnBP03nrZoGvvSrFZqT6CA21bckRP8ABF8j\nuBd41t1PBKYBq/vtvxSYHLndAjwYcDwiEgPvP3k4n3nfZJ5aXMP9L66PdzgJpzPUw/Z9bYwrTYxE\nEFhnsZkVA+cBNwC4eyfQ2a/YZcBjHv7J8EakBjHS3XcEFZeIxMY///1ktuxp5Z4X1lGSn6WRRH3U\n7G2lx0mJpqHxQC3wiJktMbN5Ztb/VY8GtvZ5XBPZ9g5mdouZVZlZVW2tJrkSSQZpacZ3PnI67ztp\nGF/+9QqeeWt7vENKGJsj1xCcUJYYNYIgE0EGMBN40N1nAC3A3cdyIHd/yN0r3b2yvLw8mjGKSIAy\n09O4/2MzOWNcKZ/7+VJeWrs73iElhM114aGjYxNg6CgEmwhqgBp3Xxh5vIBwYuhrGzCmz+OKyDYR\nGSRyMtOZd0Mlk4cXcvv8xazY1hDvkOJuU30r+VnplBVkxTsUIMBE4O47ga1mNjWy6UJgVb9izwDX\nR0YPzQYa1D8gMvgU5WTy6JwzKMnN5JM/fTPl1z3esqeVsUPz4z79dK+gRw3dBcw3s2XAdODbZnab\nmd0W2f97oBpYD/wYuD3geEQkToYX5fCTOWfQ0tHNnEfepKk9daeuTqShoxBwInD3pZG2/dPd/XJ3\n3+vuc919bmS/u/sd7j7R3U9z96og4xGR+DpxRBEPfHwmb+9u5o4nltDV3RPvkGKuu8fZuidxLiYD\nXVksIjF23pRyvnn5qby8rpav/6Z/a/Hgt6Ohja5uZ1wC1Qg06ZyIxNw1Z46luraZH7+ykRNHFvLx\ns1LnGoPN9eGho4mUCFQjEJG4uPvSkzh/ajlf+fVKXt9QH+9wYubA9NNqGhKRFJeeZtx3zQzGDc3j\n9vmL2Bq5yGqw21LfSlZGWkKsVdxLiUBE4qYoJ5N5nziD7h7npp9WpcRIok31LYwtzSMtLTGGjoIS\ngYjE2fiyfB74+CzW1zbzz08uITTIRxJtrm9NqKGjoEQgIgng3MllfO3Dp/DntbV86/f9JykePNyd\nzfWtCTO1RC+NGhKRhHDt7HFU17bwk1c3MqG8YFDOVlrb1EFbV3fCTDbXS4lARBLGlz54EpvqW/jq\nMysZV5rHeVMG1ySTm/YPHU2sGoGahkQkYfSOJJo8rIA7n1i8f4H3weLAgvWJVSNQIhCRhFKQncFD\n11ViZtz6+CJaO0PxDilq1uxsIjsjjdFDcuMdyjsoEYhIwhk7NI97r57O2l1NfPGp5YNm3eNFm/cy\nraKEzPTE+upNrGhERCLOnzqML1w0ld+8tZ2H/7ox3uEct/aublZub2DGuJJ4h/IuSgQikrBuP38i\nF58ynP/4wxr+tHpXvMM5Liu2NdDV7cwaOyTeobyLEoGIJCwz4/tXTeOUUUXc9rNFvLAqeZPBos17\nAZg5TolAROSoFOZk8vgnz+LkUcV86meLeHbFzniHdEwWb9nLuKF5lBVkxzuUd1EiEJGEV5ybyeOf\nPJPTKoq584nF/GF5cq1o6+4s2rwvIZuFQIlARJJEUU4mj914JtPGlHDXk0uSqplo65426po7ErJZ\nCJQIRCSJFOZk8uicMzhldDF3zF/My+tq4x3SEVm8JdI/oBqBiMjxK8zJ5LE5ZzJxWAG3PF7FG9WJ\nv6jNos17yc9KZ+qIwniHMiAlAhFJOsV54T6DiiF5fPLRN/ePyElUizbvZcbYIaQn0BoEfSkRiEhS\nKivIZv5NZ1FemM11Dy/k1fV18Q5pQM0dIdbsbGTm2MS7kKxXoInAzDaZ2XIzW2pmVQPsLzaz35jZ\nW2a20szmBBmPiAwuw4ty+MWtZzNmSB5zHnmT51cm3tDSZVv30eOJef1Ar1jUCC5w9+nuXjnAvjuA\nVe4+DTgfuMfMsmIQk4gMEsOKcvj5rbM5eVQRn5q/mKcX18Q7pHfobbaakaAdxRD/piEHCs3MgAJg\nDzB4phoUkZgoycti/k1ncdb4Uj73i7d47bmFcPvtUFQEaWnhf2+/HTZsiHlsi7bsZfKwAopzM2N+\n7iMVdCJw4HkzW2Rmtwyw/37gJGA7sBz4tLu/a8FSM7vFzKrMrKq2NjmGi4lIbOVnZ/CTG87g+r2r\nmPGh9+Lz5kFTE7iH/503D04/Hf7wh5jF1NPjLNmyj1kJ3CwEwSeCc919JnApcIeZnddv/8XAUmAU\nMB2438yK+h/E3R9y90p3rywvH1wrFolI9ORs2cRXH/8quV0dWFfXO3d2dUFrK1x5ZcxqBq9tqKeh\nrYvZE4bG5HzHKtBE4O7bIv/uBn4FnNmvyBzgaQ9bD2wETgwyJhEZxO65h7RQ16HLdHXBD34Qk3Ae\n/ms1ZQVZXHLqiJic71gFlrsXdEUAAAs4SURBVAjMLN/MCnvvAxcBK/oV2wJcGCkzHJgKVAcVk4gM\ncj/7WfiL/lC6uuDxxwMPZf3uZv68tpZrZ48jJzM98PMdjyAXrx8O/CrcD0wG8IS7P2tmtwG4+1zg\nG8CjZrYcMOCL7p6Yg4FFJPE1N0e33HF45NWNZGWkce3scYGf63gFlgjcvRqYNsD2uX3ubydcUxAR\nOX4FBeGO4SMpF6C9LZ08tbiGy6ePSshpp/uL9/BREZHoufZayDzMMM3MTLjuukDDeOJvW2jv6uHG\nc8cHep5oUSIQkcHj858/bCLwzEz47GcDC6Ez1MNjr2/i3EllnDjiXYMgE5ISgYgMHhMnwoIFkJf3\nroTQnZFBa0Y2D931HXrGTwgshN8v38Guxg4+mSS1AVAiEJHB5tJLYdkyuOWWd1xZnH7rrSx45Hf8\nB+P5yjMrcfeon3pPSyffe24tk4YV8N4pyXPNU5CjhkRE4mPiRLj//vCtj+vc2fbsGn70l2oKcjL4\n4iXRu2wp1N3DHfMXU9vcwS9vPZu0BJ1yeiBKBCKSMsyMuy85keb2EA++tIH8rHTuuGASkWHux+Xb\nv1/D69X13HPVNKaNSdwppweiRCAiKcXM+MZlp9LSEeL7z6/jzU17+eblpzKmNO+Yj/n04hp+8upG\nbnjPCXxkVkUUo40N9RGISMpJSzPu+eh0vvqhk6natIeLfvAy816pJtT9rjkvD+vPa3bzr08vZ/aE\nUr70wZMCiDZ4SgQikpLS04wbzhnPC597L++ZOJRv/m41l977Cr9euo3unsN3JHeGevjW71Yx59E3\nmVBewP98bCaZ6cn5lWpB9JwHqbKy0quq3rXYmYjIMXN3nlu5k3ueX8fbu5uZUJbPbedPZNa4IYwq\nziU368BcQaHuHjbWtfCFX77FWzUNXDd7HF/64EkJP5+QmS06yAJhSgQiIr16esIJ4b4X17N6R+P+\n7aX5WeRnp7OvtYum9vDaWUU5GXz3ytO55NSR8Qr3qBwqEaizWEQkIi3NuPS0kVxy6giWbN3H5voW\ntu9rZ/u+Nlo6QpTkZVGSl0lpfhbvO2k4o0py4x1yVCgRiIj0Y2bMHDuEmQm8znA0JWfPhoiIRI0S\ngYhIilMiEBFJcUoEIiIpTolARCTFKRGIiKQ4JQIRkRSnRCAikuKSbooJM6sF9gEN/XYVH2bb4e73\n/lsG1B1DaAOd/0j2999+qMf9Y+277VjijmXMfe/H473W50Ofj0PtT8bPx9HEDDDZ3YsHPLq7J90N\neOhotx3ufp9/q6IV05Hs77/9UI/7x3q8cccy5ni/1/p86PMx2D4fRxPz4c6RrE1DvzmGbYe7P9Dz\njzemI9nff/uhHg8U6/HEHcuY+96Px3utz8fR0+fjyO8nesyHPEfSNQ0Fzcyq/CAz9CWyZIxbMcdO\nMsatmGMnWWsEQXoo3gEco2SMWzHHTjLGrZhjRDUCEZEUpxqBiEiKUyIQEUlxgzoRmNlPzGy3ma04\nhufOMrPlZrbezO4zM+uz7y4zW2NmK83su9GNOpi4zeyrZrbNzJZGbh9I9Jj77P+8mbmZlUUv4sDe\n52+Y2bLIe/y8mY1Kgpi/F/k8LzOzX5lZSTRjDjDuqyJ/gz1mFrUO2uOJ9SDH+4SZvR25faLP9kN+\n7mPqWMa8JssNOA+YCaw4huf+DZgNGPAH4NLI9guAPwLZkcfDkiTurwJfSKb3OrJvDPAcsBkoS/SY\ngaI+Zf4ZmJsEMV8EZETufwf4TjJ8PoCTgKnAS0BlvGONxHFCv22lQHXk3yGR+0MO9bricRvUNQJ3\nfxnY03ebmU00s2fNbJGZvWJmJ/Z/npmNJPwH/YaH/8ceAy6P7P4U8J/u3hE5x+4kiTtQAcb8A+D/\nAVEf1RBEzO7e2KdofrTjDijm5909FCn6BlARzZgDjHu1u69NlFgP4mLgBXff4+57gReAS+L5tzqQ\nQZ0IDuIh4C53nwV8AXhggDKjgZo+j2si2wCmAH9nZgvN7C9mdkag0R5wvHED3Bmp/v/EzGKxGOtx\nxWxmlwHb3P2toAPt47jfZzP7lpltBT4OfDnAWHtF47PR60bCv05jIZpxB+1IYh3IaGBrn8e98SfK\n6wJSbPF6MysA3gP8sk9zXPZRHiaDcDVvNnAG8AszmxDJ6oGIUtwPAt8g/Av1G8A9hP/oA3G8MZtZ\nHvBvhJstYiJK7zPu/iXgS2b2r8CdwFeiFmQ/0Yo5cqwvASFgfnSiO+S5ohZ30A4Vq5nNAT4d2TYJ\n+L2ZdQIb3f2KWMd6rFIqERCuAe1z9+l9N5pZOrAo8vAZwl+afavHFcC2yP0a4OnIF//fzKyH8ERT\ntYkct7vv6vO8HwO/DTBeOP6YJwLjgbcif3wVwGIzO9PddyZozP3NB35PgImAKMVsZjcA/wBcGOSP\nmj6i/V4HacBYAdz9EeARADN7CbjB3Tf1KbINOL/P4wrCfQnbiP/rOiBenROxugEn0KfTB3gNuCpy\n34BpB3le/46cD0S23wZ8PXJ/CuFqnyVB3CP7lPks8L+JHnO/MpuIcmdxQO/z5D5l7gIWJEHMlwCr\ngPJoxxqLzwdR7iw+1lg5eGfxRsIdxUMi90uP9HMfq1tcThqzFwdPAjuALsK/5D9J+Ffms8BbkQ//\nlw/y3EpgBbABuJ8DV2FnAT+L7FsM/H2SxP04sBxYRviX1shEj7lfmU1Ef9RQEO/zU5HtywhP8jU6\nCWJeT/gHzdLILaojnQKM+4rIsTqAXcBz8YyVARJBZPuNkfd4PTDnaD73sbppigkRkRSXiqOGRESk\nDyUCEZEUp0QgIpLilAhERFKcEoGISIpTIpBBwcyaY3y+eWZ2cpSO1W3h2UpXmNlvDjf7p5mVmNnt\n0Ti3CGiFMhkkzKzZ3QuieLwMPzARW6D6xm5mPwXWufu3DlH+BOC37n5qLOKTwU81Ahm0zKzczJ4y\nszcjt3Mi2880s9fNbImZvWZmUyPbbzCzZ8zsReBPZna+mb1kZgssPF///N454yPbKyP3myMTzb1l\nZm+Y2fDI9omRx8vN7JtHWGt5nQOT7hWY2Z/MbHHkGJdFyvwnMDFSi/hepOy/RF7jMjP7WhTfRkkB\nSgQymN0L/MDdzwA+AsyLbF8D/J27zyA8O+i3+zxnJnClu7838ngG8BngZGACcM4A58kH3nD3acDL\nwM19zn+vu5/GO2eaHFBknp0LCV/5DdAOXOHuMwmvg3FPJBHdDWxw9+nu/i9mdhEwGTgTmA7MMrPz\nDnc+kV6pNumcpJb3ASf3mTGyKDKTZDHwUzObTHg21sw+z3nB3fvORf83d68BMLOlhOeg+Wu/83Ry\nYBK/RcD7I/fP5sAc808A3z9InLmRY48GVhOesx7Cc9B8O/Kl3hPZP3yA518UuS2JPC4gnBhePsj5\nRN5BiUAGszRgtru3991oZvcDf3b3KyLt7S/12d3S7xgdfe53M/DfTJcf6Gw7WJlDaXP36ZGpt58D\n7gDuI7yeQTkwy927zGwTkDPA8w34D3f/0VGeVwRQ05AMbs8TngEUADPrnUa4mANT/t4Q4PnfINwk\nBXD14Qq7eyvh5S0/b2YZhOPcHUkCFwDjIkWbgMI+T30OuDFS28HMRpvZsCi9BkkBSgQyWOSZWU2f\n2+cIf6lWRjpQVxGeQhzgu8B/mNkSgq0Vfwb4nJktI7xoScPhnuDuSwjPXHoN4fUMKs1sOXA94b4N\n3L0eeDUy3PR77v484aan1yNlF/DORCFySBo+KhKQSFNPm7u7mV0NXOPulx3ueSKxpj4CkeDMAu6P\njPTZR4BLg4ocD9UIRERSnPoIRERSnBKBiEiKUyIQEUlxSgQiIilOiUBEJMX9f3zxcCBiKLbTAAAA\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvIR88Hu-6JW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Check how the loss in both train and validation are getting similar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac__SvxYOpwh",
        "colab_type": "code",
        "outputId": "0e287f82-34a5-4e11-8e3e-524b23b634dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "lang_mod.fit_one_cycle(4, max_lr=2.5E-01)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>5.360335</td>\n",
              "      <td>4.139844</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>5.244286</td>\n",
              "      <td>4.462403</td>\n",
              "      <td>0.242857</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.100469</td>\n",
              "      <td>4.185408</td>\n",
              "      <td>0.328571</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.839475</td>\n",
              "      <td>4.103854</td>\n",
              "      <td>0.342857</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luL2piwH8hwa",
        "colab_type": "text"
      },
      "source": [
        "We normalize and get the new embeddings for our test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "275ZTW-t8kwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embs_v2 = get_normalized_embeddings()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTUuvMagddt5",
        "colab_type": "code",
        "outputId": "80eee7af-ca2b-47bd-9aac-c8491ad75447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "most_similar(':)', embs_v2)\n",
        "\n",
        "#print(lang_mod.predict('xxbos', n_words=20))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similar to: :)\n",
            "xxx                           0.36\n",
            "xxbos                         0.32\n",
            "?                             0.31\n",
            ":-(                           0.30\n",
            "150ppm                        0.27\n",
            ")                             0.26\n",
            "...                           0.25\n",
            "18                            0.25\n",
            "bslvyl                        0.24\n",
            ";_;                           0.24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RkQGSqYNB9v",
        "colab_type": "text"
      },
      "source": [
        "_**And woila!**_ üí• \n",
        "Now the word `:)` is related to other words which make perfect sense... they are also emojies!\n",
        "\n",
        "As a side note, to me it's intersting to see how the emoji face is related to the token `xxbos`. It means something that we can check in practice, some mensages started with the emoji. \n",
        "\n",
        "Remeber that `xxbos` is the token for _begin of sentence_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHDgWf3BN34e",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wiM9-d2N5ZC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "We can continue train the language model, by freezen (if I'm not wrong), only two grorup of layers.\n",
        "\n",
        "By doing so, we need to have a different LR across the layers, making the impact less agreesive on the deeper layers. Otherwise we could overfit the network and cause the [Catastrophic forgetting](https://en.wikipedia.org/wiki/Catastrophic_interference)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoKxvokwZKXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lang_mod.freeze_to(-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0tH2J35Qe9c",
        "colab_type": "text"
      },
      "source": [
        "We need to find the best LR again..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcGWLNVKmqME",
        "colab_type": "code",
        "outputId": "9fa32d78-9ce2-4f7e-d2f5-f507c7d70e85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "lang_mod.lr_find()\n",
        "lang_mod.recorder.plot(suggestion=True)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
            "Min numerical gradient: 4.79E-06\n",
            "Min loss divided by 10: 1.45E-02\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1/8DoCQlOdMwbLUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE3likAPETlz",
        "colab_type": "code",
        "outputId": "334ed980-db81-421b-bbb9-555b24655083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "# train the language model\n",
        "lang_mod.fit_one_cycle(3, slice(1e-2/100, 1e-2))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.334216</td>\n",
              "      <td>4.090609</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.189674</td>\n",
              "      <td>4.039083</td>\n",
              "      <td>0.314286</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.083463</td>\n",
              "      <td>3.986425</td>\n",
              "      <td>0.314286</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Knty4YoiQ8hJ",
        "colab_type": "text"
      },
      "source": [
        "Higher accuracy and lower (and stable) loss üëå "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P-J0KpfRcN5",
        "colab_type": "text"
      },
      "source": [
        "### How about checking again the sentences?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY8tTtDzRVZm",
        "colab_type": "code",
        "outputId": "435d4016-7e2e-4772-f7cf-5262d3008004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "for i in range(5):\n",
        "  print(lang_mod.predict(\"The problem usually starts when\", n_words=10))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The problem usually starts when the problem is one your xxbos Not pain ...\n",
            "The problem usually starts when you put leave u . Bcoz i 'm in\n",
            "The problem usually starts when the new year is the only world in xxbos\n",
            "The problem usually starts when you 're around , pls send my gf that\n",
            "The problem usually starts when they 're around xxbos So east i left shu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwnFnh1PRJEQ",
        "colab_type": "text"
      },
      "source": [
        "Do you notice any change respect than before?\n",
        "\n",
        "**Yes**, now the sentences are more related to SMS messages üì≤"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsSDG9HDR0fL",
        "colab_type": "text"
      },
      "source": [
        "### Saving the model... "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5Oc9hEicgLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lang_mod.save('lm_pre_unfreeze')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gjEr512R3sN",
        "colab_type": "text"
      },
      "source": [
        "And that's it! \n",
        "\n",
        "That language model will be the one used in our next blog post!\n",
        "\n",
        "We will create a classification model that, based on a text (SMS), it will assign the probability for SPAM  üïµÔ∏è‚Äç‚ôÇÔ∏èÔ∏èüì®"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IycU4l5iecbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AzM5b0Zeemm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7IBpX-lSpjv",
        "colab_type": "text"
      },
      "source": [
        "### Summing-up! üìù"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4Uh5oCbTKby",
        "colab_type": "text"
      },
      "source": [
        "We went through a process of download a pre-trained **Language Model**, checking the the sentences that it produces, and then we fine-tune this model to tailor the SPAM data semantics.\n",
        "\n",
        "This process is called: **Transfer Learning**.\n",
        "\n",
        "We do also check the similitudes across words between a known corpus (based on Wikipedia articles), and how new words representatations (embeddings) can be learnt from the context, in just a few lines of code and time.\n",
        "\n",
        "\n",
        "### Get in touch!\n",
        "\n",
        "Found us at:\n",
        "\n",
        "Pablo Zivic: [Linkedin](https://www.linkedin.com/in/pablozivic) & [twitter](https://twitter.com/ideasrapidas), and me at [linkedin](https://www.linkedin.com/in/pcasas/) & [twitter](https://twitter.com/pabloc_ds) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWAE6X5dH1tF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}